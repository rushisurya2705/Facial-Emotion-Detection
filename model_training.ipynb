{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing required libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Dropout, ReLU, Flatten, Dense\nfrom tensorflow.keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:36.900365Z","iopub.execute_input":"2023-08-17T07:47:36.901168Z","iopub.status.idle":"2023-08-17T07:47:42.300311Z","shell.execute_reply.started":"2023-08-17T07:47:36.901078Z","shell.execute_reply":"2023-08-17T07:47:42.299147Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# importing datasets\ntrain_dir = \"../input/emotion-detection-fer/train\" # Replace with appropriate path\ntest_dir = \"../input/emotion-detection-fer/test\"  ","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:42.306351Z","iopub.execute_input":"2023-08-17T07:47:42.307040Z","iopub.status.idle":"2023-08-17T07:47:42.313805Z","shell.execute_reply.started":"2023-08-17T07:47:42.307003Z","shell.execute_reply":"2023-08-17T07:47:42.312282Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"img_size=48\nepochs = 60\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:42.316998Z","iopub.execute_input":"2023-08-17T07:47:42.317687Z","iopub.status.idle":"2023-08-17T07:47:42.327839Z","shell.execute_reply.started":"2023-08-17T07:47:42.317649Z","shell.execute_reply":"2023-08-17T07:47:42.326927Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# data augmentation\ntrain_datagen = ImageDataGenerator(\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True,\n    rescale = 1./255,\n    validation_split = 0.2,\n    rotation_range = 30\n)\n\nvalidation_datagen = ImageDataGenerator(\n    rescale = 1./255\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:42.331568Z","iopub.execute_input":"2023-08-17T07:47:42.331951Z","iopub.status.idle":"2023-08-17T07:47:42.338990Z","shell.execute_reply.started":"2023-08-17T07:47:42.331923Z","shell.execute_reply":"2023-08-17T07:47:42.337880Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    directory = train_dir,\n    target_size = (img_size,img_size),\n    shuffle = True,\n    batch_size = 64,\n    color_mode = \"grayscale\",\n    class_mode = \"categorical\",\n    subset = \"training\"\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    directory = train_dir,\n    target_size = (img_size,img_size),\n    shuffle = True,\n    batch_size = 64,\n    color_mode = \"grayscale\",\n    class_mode = \"categorical\",\n    subset = \"validation\"\n)\n\ntest_generator = validation_datagen.flow_from_directory(\n    directory = test_dir,\n    shuffle = True,\n    target_size = (48, 48),\n    batch_size = 64,\n    color_mode = 'grayscale',\n    class_mode = 'categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:42.340752Z","iopub.execute_input":"2023-08-17T07:47:42.341172Z","iopub.status.idle":"2023-08-17T07:47:56.213089Z","shell.execute_reply.started":"2023-08-17T07:47:42.341137Z","shell.execute_reply":"2023-08-17T07:47:56.211185Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Found 22968 images belonging to 7 classes.\nFound 5741 images belonging to 7 classes.\nFound 7178 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"def model1(inputLayer):\n    x = Conv2D(64, kernel_size=(3, 3))(inputLayer[0])\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2,2), strides=(2, 2))(x)\n    x = ReLU()(x)\n    \n    x = Conv2D(64, kernel_size=(3, 3))(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2,2), strides=(2, 2))(x)\n    x = ReLU()(x)\n    \n    x = Conv2D(128, kernel_size=(3, 3))(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2,2), strides=(2, 2))(x)\n    x = ReLU()(x)\n    \n    x = Conv2D(128, kernel_size=(3, 3))(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2,2), strides=(2, 2))(x)\n    x = ReLU()(x)\n    \n    x = Flatten()(x)\n    \n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    \n    x = Dense(7, activation='softmax')(x)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:56.214786Z","iopub.execute_input":"2023-08-17T07:47:56.215154Z","iopub.status.idle":"2023-08-17T07:47:56.230324Z","shell.execute_reply.started":"2023-08-17T07:47:56.215118Z","shell.execute_reply":"2023-08-17T07:47:56.229314Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"input_1 = Input(shape=(48, 48, 1), name=\"input_1\")\nz_1 = model1([input_1])\nmodel_1 = Model(inputs=[input_1], outputs=[z_1])\n\nmodel_1.summary()\n\nmodel_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:56.231817Z","iopub.execute_input":"2023-08-17T07:47:56.232279Z","iopub.status.idle":"2023-08-17T07:47:58.878635Z","shell.execute_reply.started":"2023-08-17T07:47:56.232242Z","shell.execute_reply":"2023-08-17T07:47:58.877525Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 48, 48, 1)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 46, 46, 64)        640       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 46, 46, 64)        256       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 23, 23, 64)        0         \n_________________________________________________________________\nre_lu (ReLU)                 (None, 23, 23, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 21, 21, 64)        36928     \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 21, 21, 64)        256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 10, 10, 64)        0         \n_________________________________________________________________\nre_lu_1 (ReLU)               (None, 10, 10, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 8, 8, 128)         512       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n_________________________________________________________________\nre_lu_2 (ReLU)               (None, 4, 4, 128)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 2, 2, 128)         147584    \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 2, 2, 128)         512       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n_________________________________________________________________\nre_lu_3 (ReLU)               (None, 1, 1, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 128)               0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               66048     \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 7)                 3591      \n=================================================================\nTotal params: 592,839\nTrainable params: 592,071\nNon-trainable params: 768\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def model2(inputLayer):\n    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputLayer[0])\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n    x = Dropout(0.25)(x)\n    \n    x = Conv2D(128, (5, 5), padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n    x = Dropout(0.25)(x)\n    \n    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n    x = Dropout(0.25)(x)\n    \n    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(2, 2))(x)\n    x = Dropout(0.25)(x)\n    \n    x = Flatten()(x)\n    \n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.25)(x)\n    \n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.25)(x)\n    \n    x = Dense(7, activation='softmax')(x)\n    \n    return x","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:58.880163Z","iopub.execute_input":"2023-08-17T07:47:58.881725Z","iopub.status.idle":"2023-08-17T07:47:58.895710Z","shell.execute_reply.started":"2023-08-17T07:47:58.881685Z","shell.execute_reply":"2023-08-17T07:47:58.894420Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"input_2 = Input(shape=(48, 48, 1), name=\"input_2\")\nz_2 = model2([input_2])\nmodel_2 = Model(inputs=[input_2], outputs=[z_2])\n\nmodel_2.summary()\n\nmodel_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:58.896895Z","iopub.execute_input":"2023-08-17T07:47:58.897280Z","iopub.status.idle":"2023-08-17T07:47:59.070795Z","shell.execute_reply.started":"2023-08-17T07:47:58.897242Z","shell.execute_reply":"2023-08-17T07:47:59.069793Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 48, 48, 1)]       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 48, 48, 32)        320       \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 48, 48, 64)        18496     \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 24, 24, 64)        0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 24, 24, 128)       204928    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 12, 12, 128)       0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 12, 12, 512)       590336    \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 12, 12, 512)       2048      \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 6, 6, 512)         0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 6, 6, 512)         0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 6, 6, 512)         2048      \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 3, 3, 512)         0         \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 3, 3, 512)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 4608)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 256)               1179904   \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 256)               1024      \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 512)               131584    \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 512)               2048      \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 7)                 3591      \n=================================================================\nTotal params: 4,496,903\nTrainable params: 4,492,935\nNon-trainable params: 3,968\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# training model 2\nmodel_2.fit(train_generator,epochs = epochs, validation_data = validation_generator)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T07:47:59.072155Z","iopub.execute_input":"2023-08-17T07:47:59.073702Z","iopub.status.idle":"2023-08-17T08:25:06.468393Z","shell.execute_reply.started":"2023-08-17T07:47:59.073664Z","shell.execute_reply":"2023-08-17T08:25:06.467359Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/60\n359/359 [==============================] - 86s 219ms/step - loss: 9.2972 - accuracy: 0.1887 - val_loss: 8.7952 - val_accuracy: 0.2219\nEpoch 2/60\n359/359 [==============================] - 35s 98ms/step - loss: 8.2232 - accuracy: 0.2169 - val_loss: 7.5866 - val_accuracy: 0.2390\nEpoch 3/60\n359/359 [==============================] - 36s 99ms/step - loss: 7.1768 - accuracy: 0.2354 - val_loss: 6.5137 - val_accuracy: 0.2783\nEpoch 4/60\n359/359 [==============================] - 36s 100ms/step - loss: 6.1540 - accuracy: 0.2552 - val_loss: 5.7025 - val_accuracy: 0.2625\nEpoch 5/60\n359/359 [==============================] - 35s 98ms/step - loss: 5.2477 - accuracy: 0.2715 - val_loss: 4.7849 - val_accuracy: 0.2865\nEpoch 6/60\n359/359 [==============================] - 36s 99ms/step - loss: 4.4752 - accuracy: 0.2928 - val_loss: 4.3133 - val_accuracy: 0.2900\nEpoch 7/60\n359/359 [==============================] - 35s 98ms/step - loss: 3.8524 - accuracy: 0.3129 - val_loss: 3.7980 - val_accuracy: 0.3066\nEpoch 8/60\n359/359 [==============================] - 35s 99ms/step - loss: 3.3508 - accuracy: 0.3375 - val_loss: 3.0624 - val_accuracy: 0.3640\nEpoch 9/60\n359/359 [==============================] - 36s 100ms/step - loss: 2.9532 - accuracy: 0.3604 - val_loss: 2.6998 - val_accuracy: 0.4137\nEpoch 10/60\n359/359 [==============================] - 36s 100ms/step - loss: 2.6371 - accuracy: 0.3942 - val_loss: 2.5656 - val_accuracy: 0.3681\nEpoch 11/60\n359/359 [==============================] - 36s 101ms/step - loss: 2.4116 - accuracy: 0.4107 - val_loss: 2.2035 - val_accuracy: 0.4644\nEpoch 12/60\n359/359 [==============================] - 36s 100ms/step - loss: 2.2262 - accuracy: 0.4355 - val_loss: 2.1992 - val_accuracy: 0.4435\nEpoch 13/60\n359/359 [==============================] - 35s 97ms/step - loss: 2.0858 - accuracy: 0.4504 - val_loss: 1.9744 - val_accuracy: 0.4715\nEpoch 14/60\n359/359 [==============================] - 35s 98ms/step - loss: 1.9873 - accuracy: 0.4641 - val_loss: 1.8980 - val_accuracy: 0.4839\nEpoch 15/60\n359/359 [==============================] - 35s 97ms/step - loss: 1.8915 - accuracy: 0.4816 - val_loss: 1.8018 - val_accuracy: 0.5203\nEpoch 16/60\n359/359 [==============================] - 34s 96ms/step - loss: 1.8226 - accuracy: 0.4932 - val_loss: 1.7430 - val_accuracy: 0.5215\nEpoch 17/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.7568 - accuracy: 0.5032 - val_loss: 1.6653 - val_accuracy: 0.5398\nEpoch 18/60\n359/359 [==============================] - 35s 97ms/step - loss: 1.7214 - accuracy: 0.5110 - val_loss: 1.6287 - val_accuracy: 0.5551\nEpoch 19/60\n359/359 [==============================] - 36s 101ms/step - loss: 1.6748 - accuracy: 0.5199 - val_loss: 1.8034 - val_accuracy: 0.5111\nEpoch 20/60\n359/359 [==============================] - 37s 102ms/step - loss: 1.6453 - accuracy: 0.5237 - val_loss: 1.5788 - val_accuracy: 0.5558\nEpoch 21/60\n359/359 [==============================] - 38s 105ms/step - loss: 1.6113 - accuracy: 0.5350 - val_loss: 1.5299 - val_accuracy: 0.5624\nEpoch 22/60\n359/359 [==============================] - 38s 105ms/step - loss: 1.5836 - accuracy: 0.5394 - val_loss: 1.5329 - val_accuracy: 0.5666\nEpoch 23/60\n359/359 [==============================] - 36s 101ms/step - loss: 1.5621 - accuracy: 0.5461 - val_loss: 1.5320 - val_accuracy: 0.5584\nEpoch 24/60\n359/359 [==============================] - 35s 97ms/step - loss: 1.5362 - accuracy: 0.5514 - val_loss: 1.4734 - val_accuracy: 0.5806\nEpoch 25/60\n359/359 [==============================] - 35s 97ms/step - loss: 1.5256 - accuracy: 0.5556 - val_loss: 1.6166 - val_accuracy: 0.5370\nEpoch 26/60\n359/359 [==============================] - 36s 100ms/step - loss: 1.5146 - accuracy: 0.5593 - val_loss: 1.4572 - val_accuracy: 0.5901\nEpoch 27/60\n359/359 [==============================] - 36s 100ms/step - loss: 1.4952 - accuracy: 0.5625 - val_loss: 1.4485 - val_accuracy: 0.5941\nEpoch 28/60\n359/359 [==============================] - 37s 102ms/step - loss: 1.4928 - accuracy: 0.5656 - val_loss: 1.5150 - val_accuracy: 0.5701\nEpoch 29/60\n359/359 [==============================] - 37s 103ms/step - loss: 1.4840 - accuracy: 0.5733 - val_loss: 1.4425 - val_accuracy: 0.5961\nEpoch 30/60\n359/359 [==============================] - 36s 100ms/step - loss: 1.4699 - accuracy: 0.5763 - val_loss: 1.4519 - val_accuracy: 0.5842\nEpoch 31/60\n359/359 [==============================] - 38s 105ms/step - loss: 1.4657 - accuracy: 0.5767 - val_loss: 1.4507 - val_accuracy: 0.5879\nEpoch 32/60\n359/359 [==============================] - 43s 121ms/step - loss: 1.4447 - accuracy: 0.5805 - val_loss: 1.4506 - val_accuracy: 0.5886\nEpoch 33/60\n359/359 [==============================] - 36s 100ms/step - loss: 1.4449 - accuracy: 0.5782 - val_loss: 1.4057 - val_accuracy: 0.6077\nEpoch 34/60\n359/359 [==============================] - 37s 104ms/step - loss: 1.4415 - accuracy: 0.5837 - val_loss: 1.4739 - val_accuracy: 0.5745\nEpoch 35/60\n359/359 [==============================] - 36s 101ms/step - loss: 1.4323 - accuracy: 0.5873 - val_loss: 1.4129 - val_accuracy: 0.5992\nEpoch 36/60\n359/359 [==============================] - 36s 101ms/step - loss: 1.4322 - accuracy: 0.5887 - val_loss: 1.4590 - val_accuracy: 0.5827\nEpoch 37/60\n359/359 [==============================] - 37s 104ms/step - loss: 1.4301 - accuracy: 0.5935 - val_loss: 1.4212 - val_accuracy: 0.6041\nEpoch 38/60\n359/359 [==============================] - 36s 100ms/step - loss: 1.4180 - accuracy: 0.5944 - val_loss: 1.4099 - val_accuracy: 0.5941\nEpoch 39/60\n359/359 [==============================] - 35s 97ms/step - loss: 1.4145 - accuracy: 0.5955 - val_loss: 1.3852 - val_accuracy: 0.6140\nEpoch 40/60\n359/359 [==============================] - 34s 96ms/step - loss: 1.4119 - accuracy: 0.5928 - val_loss: 1.4151 - val_accuracy: 0.5959\nEpoch 41/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.4110 - accuracy: 0.5994 - val_loss: 1.4154 - val_accuracy: 0.6020\nEpoch 42/60\n359/359 [==============================] - 34s 96ms/step - loss: 1.4050 - accuracy: 0.5993 - val_loss: 1.3990 - val_accuracy: 0.6093\nEpoch 43/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.3999 - accuracy: 0.6018 - val_loss: 1.3766 - val_accuracy: 0.6194\nEpoch 44/60\n359/359 [==============================] - 35s 98ms/step - loss: 1.3926 - accuracy: 0.6029 - val_loss: 1.4050 - val_accuracy: 0.6116\nEpoch 45/60\n359/359 [==============================] - 36s 100ms/step - loss: 1.3930 - accuracy: 0.6043 - val_loss: 1.3674 - val_accuracy: 0.6191\nEpoch 46/60\n359/359 [==============================] - 36s 100ms/step - loss: 1.3919 - accuracy: 0.6067 - val_loss: 1.3925 - val_accuracy: 0.6091\nEpoch 47/60\n359/359 [==============================] - 35s 98ms/step - loss: 1.3946 - accuracy: 0.6095 - val_loss: 1.3967 - val_accuracy: 0.6187\nEpoch 48/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.3829 - accuracy: 0.6101 - val_loss: 1.4071 - val_accuracy: 0.6044\nEpoch 49/60\n359/359 [==============================] - 35s 96ms/step - loss: 1.3756 - accuracy: 0.6095 - val_loss: 1.4206 - val_accuracy: 0.6030\nEpoch 50/60\n359/359 [==============================] - 35s 97ms/step - loss: 1.3693 - accuracy: 0.6139 - val_loss: 1.3953 - val_accuracy: 0.6110\nEpoch 51/60\n359/359 [==============================] - 36s 99ms/step - loss: 1.3686 - accuracy: 0.6107 - val_loss: 1.3885 - val_accuracy: 0.6133\nEpoch 52/60\n359/359 [==============================] - 35s 97ms/step - loss: 1.3698 - accuracy: 0.6161 - val_loss: 1.3658 - val_accuracy: 0.6274\nEpoch 53/60\n359/359 [==============================] - 36s 100ms/step - loss: 1.3623 - accuracy: 0.6149 - val_loss: 1.3992 - val_accuracy: 0.6182\nEpoch 54/60\n359/359 [==============================] - 37s 103ms/step - loss: 1.3601 - accuracy: 0.6146 - val_loss: 1.3985 - val_accuracy: 0.6206\nEpoch 55/60\n359/359 [==============================] - 36s 102ms/step - loss: 1.3531 - accuracy: 0.6165 - val_loss: 1.3997 - val_accuracy: 0.6133\nEpoch 56/60\n359/359 [==============================] - 36s 101ms/step - loss: 1.3682 - accuracy: 0.6193 - val_loss: 1.3844 - val_accuracy: 0.6198\nEpoch 57/60\n359/359 [==============================] - 35s 98ms/step - loss: 1.3569 - accuracy: 0.6202 - val_loss: 1.3669 - val_accuracy: 0.6241\nEpoch 58/60\n359/359 [==============================] - 38s 106ms/step - loss: 1.3600 - accuracy: 0.6220 - val_loss: 1.3841 - val_accuracy: 0.6150\nEpoch 59/60\n359/359 [==============================] - 35s 98ms/step - loss: 1.3581 - accuracy: 0.6206 - val_loss: 1.3817 - val_accuracy: 0.6231\nEpoch 60/60\n359/359 [==============================] - 36s 100ms/step - loss: 1.3541 - accuracy: 0.6258 - val_loss: 1.3508 - val_accuracy: 0.6321\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7dfe8f885d50>"},"metadata":{}}]},{"cell_type":"code","source":"# training model 1\nmodel_1.fit(train_generator,epochs = epochs, validation_data = validation_generator)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T08:25:06.470626Z","iopub.execute_input":"2023-08-17T08:25:06.471265Z","iopub.status.idle":"2023-08-17T08:59:00.900355Z","shell.execute_reply.started":"2023-08-17T08:25:06.471227Z","shell.execute_reply":"2023-08-17T08:59:00.899260Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/60\n359/359 [==============================] - 35s 96ms/step - loss: 1.7819 - accuracy: 0.2647 - val_loss: 1.8419 - val_accuracy: 0.1810\nEpoch 2/60\n359/359 [==============================] - 35s 97ms/step - loss: 1.6474 - accuracy: 0.3441 - val_loss: 1.5890 - val_accuracy: 0.3832\nEpoch 3/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.5642 - accuracy: 0.3846 - val_loss: 1.5281 - val_accuracy: 0.4017\nEpoch 4/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.5096 - accuracy: 0.4144 - val_loss: 1.5036 - val_accuracy: 0.4125\nEpoch 5/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.4516 - accuracy: 0.4369 - val_loss: 1.4216 - val_accuracy: 0.4497\nEpoch 6/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.4183 - accuracy: 0.4500 - val_loss: 1.4822 - val_accuracy: 0.4358\nEpoch 7/60\n359/359 [==============================] - 33s 92ms/step - loss: 1.3848 - accuracy: 0.4689 - val_loss: 1.3723 - val_accuracy: 0.4740\nEpoch 8/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.3580 - accuracy: 0.4788 - val_loss: 1.3646 - val_accuracy: 0.4802\nEpoch 9/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.3315 - accuracy: 0.4899 - val_loss: 1.3492 - val_accuracy: 0.4823\nEpoch 10/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.3185 - accuracy: 0.4982 - val_loss: 1.3331 - val_accuracy: 0.4917\nEpoch 11/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.3003 - accuracy: 0.5027 - val_loss: 1.3400 - val_accuracy: 0.4926\nEpoch 12/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.2823 - accuracy: 0.5100 - val_loss: 1.2720 - val_accuracy: 0.5118\nEpoch 13/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.2672 - accuracy: 0.5192 - val_loss: 1.2767 - val_accuracy: 0.5179\nEpoch 14/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.2532 - accuracy: 0.5209 - val_loss: 1.2877 - val_accuracy: 0.5135\nEpoch 15/60\n359/359 [==============================] - 34s 93ms/step - loss: 1.2334 - accuracy: 0.5303 - val_loss: 1.2476 - val_accuracy: 0.5297\nEpoch 16/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.2282 - accuracy: 0.5303 - val_loss: 1.2651 - val_accuracy: 0.5186\nEpoch 17/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.2113 - accuracy: 0.5361 - val_loss: 1.2438 - val_accuracy: 0.5285\nEpoch 18/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.2046 - accuracy: 0.5429 - val_loss: 1.2554 - val_accuracy: 0.5274\nEpoch 19/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.1924 - accuracy: 0.5459 - val_loss: 1.2155 - val_accuracy: 0.5349\nEpoch 20/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.1890 - accuracy: 0.5474 - val_loss: 1.2063 - val_accuracy: 0.5395\nEpoch 21/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.1763 - accuracy: 0.5522 - val_loss: 1.2130 - val_accuracy: 0.5445\nEpoch 22/60\n359/359 [==============================] - 34s 93ms/step - loss: 1.1736 - accuracy: 0.5526 - val_loss: 1.2028 - val_accuracy: 0.5492\nEpoch 23/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.1546 - accuracy: 0.5583 - val_loss: 1.2673 - val_accuracy: 0.5208\nEpoch 24/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.1590 - accuracy: 0.5606 - val_loss: 1.2034 - val_accuracy: 0.5518\nEpoch 25/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.1470 - accuracy: 0.5662 - val_loss: 1.1979 - val_accuracy: 0.5548\nEpoch 26/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.1435 - accuracy: 0.5652 - val_loss: 1.1786 - val_accuracy: 0.5490\nEpoch 27/60\n359/359 [==============================] - 35s 99ms/step - loss: 1.1383 - accuracy: 0.5641 - val_loss: 1.1974 - val_accuracy: 0.5438\nEpoch 28/60\n359/359 [==============================] - 35s 97ms/step - loss: 1.1278 - accuracy: 0.5719 - val_loss: 1.1671 - val_accuracy: 0.5576\nEpoch 29/60\n359/359 [==============================] - 35s 98ms/step - loss: 1.1150 - accuracy: 0.5735 - val_loss: 1.1789 - val_accuracy: 0.5522\nEpoch 30/60\n359/359 [==============================] - 35s 98ms/step - loss: 1.1185 - accuracy: 0.5751 - val_loss: 1.1847 - val_accuracy: 0.5478\nEpoch 31/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.1145 - accuracy: 0.5782 - val_loss: 1.2383 - val_accuracy: 0.5271\nEpoch 32/60\n359/359 [==============================] - 34s 96ms/step - loss: 1.0991 - accuracy: 0.5782 - val_loss: 1.1522 - val_accuracy: 0.5673\nEpoch 33/60\n359/359 [==============================] - 35s 96ms/step - loss: 1.0970 - accuracy: 0.5811 - val_loss: 1.1427 - val_accuracy: 0.5659\nEpoch 34/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.0935 - accuracy: 0.5849 - val_loss: 1.1682 - val_accuracy: 0.5609\nEpoch 35/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.0857 - accuracy: 0.5883 - val_loss: 1.1509 - val_accuracy: 0.5689\nEpoch 36/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.0789 - accuracy: 0.5912 - val_loss: 1.1169 - val_accuracy: 0.5854\nEpoch 37/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.0771 - accuracy: 0.5900 - val_loss: 1.1398 - val_accuracy: 0.5685\nEpoch 38/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.0710 - accuracy: 0.5938 - val_loss: 1.1189 - val_accuracy: 0.5753\nEpoch 39/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.0685 - accuracy: 0.5926 - val_loss: 1.1200 - val_accuracy: 0.5811\nEpoch 40/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.0669 - accuracy: 0.5933 - val_loss: 1.1168 - val_accuracy: 0.5792\nEpoch 41/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.0681 - accuracy: 0.5930 - val_loss: 1.1960 - val_accuracy: 0.5570\nEpoch 42/60\n359/359 [==============================] - 33s 92ms/step - loss: 1.0553 - accuracy: 0.6008 - val_loss: 1.1347 - val_accuracy: 0.5813\nEpoch 43/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.0519 - accuracy: 0.6016 - val_loss: 1.1185 - val_accuracy: 0.5720\nEpoch 44/60\n359/359 [==============================] - 34s 93ms/step - loss: 1.0544 - accuracy: 0.6012 - val_loss: 1.1766 - val_accuracy: 0.5689\nEpoch 45/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.0492 - accuracy: 0.5988 - val_loss: 1.1179 - val_accuracy: 0.5849\nEpoch 46/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.0400 - accuracy: 0.6023 - val_loss: 1.1141 - val_accuracy: 0.5825\nEpoch 47/60\n359/359 [==============================] - 34s 94ms/step - loss: 1.0438 - accuracy: 0.6046 - val_loss: 1.1083 - val_accuracy: 0.5788\nEpoch 48/60\n359/359 [==============================] - 34s 95ms/step - loss: 1.0276 - accuracy: 0.6084 - val_loss: 1.1508 - val_accuracy: 0.5671\nEpoch 49/60\n359/359 [==============================] - 33s 92ms/step - loss: 1.0297 - accuracy: 0.6082 - val_loss: 1.0952 - val_accuracy: 0.5835\nEpoch 50/60\n359/359 [==============================] - 33s 92ms/step - loss: 1.0229 - accuracy: 0.6109 - val_loss: 1.1844 - val_accuracy: 0.5570\nEpoch 51/60\n359/359 [==============================] - 33s 91ms/step - loss: 1.0197 - accuracy: 0.6121 - val_loss: 1.0932 - val_accuracy: 0.5868\nEpoch 52/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.0193 - accuracy: 0.6140 - val_loss: 1.0993 - val_accuracy: 0.5861\nEpoch 53/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.0117 - accuracy: 0.6189 - val_loss: 1.1042 - val_accuracy: 0.5860\nEpoch 54/60\n359/359 [==============================] - 33s 92ms/step - loss: 1.0153 - accuracy: 0.6156 - val_loss: 1.1091 - val_accuracy: 0.5767\nEpoch 55/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.0092 - accuracy: 0.6165 - val_loss: 1.1084 - val_accuracy: 0.5914\nEpoch 56/60\n359/359 [==============================] - 33s 92ms/step - loss: 1.0104 - accuracy: 0.6183 - val_loss: 1.1436 - val_accuracy: 0.5687\nEpoch 57/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.0011 - accuracy: 0.6171 - val_loss: 1.0865 - val_accuracy: 0.5982\nEpoch 58/60\n359/359 [==============================] - 33s 93ms/step - loss: 0.9996 - accuracy: 0.6224 - val_loss: 1.1157 - val_accuracy: 0.5872\nEpoch 59/60\n359/359 [==============================] - 33s 93ms/step - loss: 1.0001 - accuracy: 0.6203 - val_loss: 1.0813 - val_accuracy: 0.5952\nEpoch 60/60\n359/359 [==============================] - 33s 92ms/step - loss: 0.9949 - accuracy: 0.6199 - val_loss: 1.0818 - val_accuracy: 0.5922\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7dfe7013bd10>"},"metadata":{}}]},{"cell_type":"code","source":"# evaluating model 1\nmodel_1.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T08:59:00.903507Z","iopub.execute_input":"2023-08-17T08:59:00.904673Z","iopub.status.idle":"2023-08-17T08:59:31.236618Z","shell.execute_reply.started":"2023-08-17T08:59:00.904633Z","shell.execute_reply":"2023-08-17T08:59:31.235688Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"113/113 [==============================] - 30s 267ms/step - loss: 1.0719 - accuracy: 0.5958\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[1.0718775987625122, 0.5958484411239624]"},"metadata":{}}]},{"cell_type":"code","source":"# evaluating model 2\nmodel_2.evaluate(test_generator)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T08:59:31.241719Z","iopub.execute_input":"2023-08-17T08:59:31.242063Z","iopub.status.idle":"2023-08-17T08:59:36.643428Z","shell.execute_reply.started":"2023-08-17T08:59:31.242028Z","shell.execute_reply":"2023-08-17T08:59:36.642131Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"113/113 [==============================] - 5s 47ms/step - loss: 1.3315 - accuracy: 0.6410\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[1.3314627408981323, 0.6409863233566284]"},"metadata":{}}]},{"cell_type":"code","source":"# saving model_1 in .json file\nmodel_json_1 = model_1.to_json()\nwith open('my_new_model_1.json', 'w') as file:\n    file.write(model_json_1)\n\n# saving weights in .h5 file\nmodel_1.save_weights('my_new_model_1.h5')","metadata":{"execution":{"iopub.status.busy":"2023-08-17T08:59:36.646198Z","iopub.execute_input":"2023-08-17T08:59:36.646536Z","iopub.status.idle":"2023-08-17T08:59:36.699886Z","shell.execute_reply.started":"2023-08-17T08:59:36.646505Z","shell.execute_reply":"2023-08-17T08:59:36.698864Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# saving model_2 in .json file\nmodel_json_2 = model_2.to_json()\nwith open('my_new_model_2.json', 'w') as file:\n    file.write(model_json_2)\n\n# saving weights in .h5 file\nmodel_2.save_weights('my_new_model_2.h5')","metadata":{"execution":{"iopub.status.busy":"2023-08-17T08:59:36.701875Z","iopub.execute_input":"2023-08-17T08:59:36.702284Z","iopub.status.idle":"2023-08-17T08:59:36.787532Z","shell.execute_reply.started":"2023-08-17T08:59:36.702245Z","shell.execute_reply":"2023-08-17T08:59:36.786506Z"},"trusted":true},"execution_count":15,"outputs":[]}]}